{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#reading input video frame by frame by opencv\n",
    "cap = cv2.VideoCapture('video1.avi')\n",
    "\n",
    "#saving first frame of the video as background image\n",
    "_, BG= cap.read()\n",
    "BG=cv2.cvtColor(BG,cv2.COLOR_BGR2GRAY)            #changing backgroung image to gray scale\n",
    "cv2.equalizeHist(BG)                              #increasing contrast of the image\n",
    "BG=cv2.GaussianBlur(BG,(7,7),0)                   #bluring the edges of the image \n",
    "cv2.imshow('BG', BG)\n",
    "  #circular dictionary initiaization which has frame no. as key and list centroids of blobs as value \n",
    "fgcnts={}\n",
    "frameno=0\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    # reading frame from video one by one\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==0:                    #break the if it is last frame\n",
    "        break\n",
    "        \n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)        #change frame to gray scale\n",
    "    cv2.equalizeHist(gray)                             # increasing cntrast of frame\n",
    "    gray=cv2.GaussianBlur(gray,(7,7),0)                #bluring the edges \n",
    "    \n",
    "    # taking absolute difference of background image with current frame\n",
    "    fgmask=cv2.absdiff(gray.astype(np.uint8), BG.astype(np.uint8))\n",
    "    \n",
    "    #applying threshold on subtacted image\n",
    "    rt,fgmask=cv2.threshold(fgmask.astype(np.uint8), 25, 255, cv2.THRESH_BINARY)\n",
    "  \n",
    "    #applying mrphological operation both erosion and dilation  \n",
    "    kernel2 = np.ones((8,8),np.uint8)   #higher the kernel, eg (10,10), more will be eroded or dilated\n",
    "    thresh2 = cv2.morphologyEx(fgmask,cv2.MORPH_CLOSE, kernel2,iterations=3)\n",
    "    #applying edge detector after morphological operation \n",
    "    edged = cv2.Canny(thresh2, 30,50)\n",
    "    \n",
    "   #finding boundaries of all blobs of the frame\n",
    "    im2, contours, hierarchy = cv2.findContours(edged,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    #initialising list of centroids of blobs\n",
    "    fgcnts[frameno%1000]=[]\n",
    "    for contour in contours:\n",
    "        #finding the centroid of each blob\n",
    "        M = cv2.moments(contour)\n",
    "        if not M['m00'] == 0: \n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            centre=(cx,cy) \n",
    "            #appending the centroid to list\n",
    "            fgcnts[frameno%1000].append(centre)\n",
    "           \n",
    "        #checking for unattended object\n",
    "            if frameno>200:\n",
    "                if cv2.contourArea(contour) in range(200,15000) and centre in fgcnts[(frameno-190)%1000] and fgcnts[(frameno-100)%1000] and fgcnts[(frameno-50)%1000]:\n",
    "                    (x,y,w,h) = cv2.boundingRect(contour)\n",
    "                    cv2.rectangle(frame, (x,y), (x+w,y+h), (0, 0, 255), 2)\n",
    "                    cv2.putText(frame,'unattended object', (x,y-10),cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255),2) \n",
    "        \n",
    "    #background update: to remove the wrong prediction press key 'a'    \n",
    "    if(cv2.waitKey(1) & 0xFF == ord('a')):\n",
    "        BG[y:y+h, x:x+w]=gray[y:y+h, x:x+w] \n",
    "        \n",
    "    frameno+=1\n",
    "    cv2.imshow('result', edged  )\n",
    "    frame=cv2.resize(frame, (1500,720))          #final frame is resized to a value\n",
    "    cv2.imshow('original',frame)                #final frame is shown\n",
    "\n",
    "    #to\n",
    "    if(cv2.waitKey(1) & 0xFF == ord('q')):\n",
    "        break\n",
    "#when everything is done, release cap\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select background from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap2 = cv2.VideoCapture(0)\n",
    "while (cap2.isOpened()):\n",
    "    ret, frame = cap2.read()\n",
    "    if ret==0:\n",
    "        break\n",
    "    cv2.imshow('bg',frame)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        BG = frame\n",
    "        break  \n",
    "cap2.release()\n",
    "cv2.destroyAllWindows() \n",
    "     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
